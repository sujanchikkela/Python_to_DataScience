{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Breast Cancer Coimbra Dataset(UCI) using Logistic Regression with Scikit Learn",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 1: Data Preprocessing",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# import the Libraries\nimport numpy as np                 # used for multidimensional array\nimport pandas as pd               # used for import the dataset\nimport matplotlib.pyplot as plt   # used for plot the Graph",
      "metadata": {},
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# import the dataset\ndataset= pd.read_csv('Breast cancer.csv')\nX= dataset.iloc[:,:-1].values      # predictor attribute\ny= dataset.iloc[:,-1].values       # Target attribute",
      "metadata": {},
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Split the dataset into test set and Train set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)",
      "metadata": {},
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X= StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)",
      "metadata": {},
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 2: Building the Logistic Regression Model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# import the Logistic regression model from scikit learn\nfrom sklearn.linear_model import LogisticRegression",
      "metadata": {},
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# init the model\nLG = LogisticRegression(random_state=0)",
      "metadata": {},
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# fit the training data into our model\nLG.fit(X_train,y_train)",
      "metadata": {},
      "execution_count": 40,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "#### Part 3: Making a prediction and Visualize the result",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# predicted the result\ny_pred = LG.predict(X_test)\ny_pred",
      "metadata": {},
      "execution_count": 41,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n       1, 2], dtype=int64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Confusion metric\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\ncm",
      "metadata": {},
      "execution_count": 42,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 5,  6],\n       [ 3, 10]], dtype=int64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Accuracy score\nfrom sklearn.metrics import accuracy_score\nac=accuracy_score(y_test, y_pred)\nac",
      "metadata": {},
      "execution_count": 43,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.625"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Visualising the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, LG.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('Distance')\nplt.ylabel('Cities')\nplt.legend()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}