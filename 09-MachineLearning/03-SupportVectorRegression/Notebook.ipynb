{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 1\n########################### Data Preprocessing ############################\n\n# Importing the libraries\nimport numpy as np\nimport pandas as pd\n\n# Importing the data set\ndataset = pd.read_csv('data/beer_data.csv')\n\n\n# Printing first 10 rows of the dataset\nprint(\"\\n----------------------------\\n\",dataset.head(10))\n\n\n# Dealing with the categorical data\n\n# Spliting Cellar Temperature into Maximum and Minimum based on the given data and converting the type from str to int\n\ndataset['Minimum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(x.split('-')[0].strip()))\ndataset['Maximum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(x.split('-')[1].strip()))\n\n# New dataset with selected features\ndataset = dataset[['ABV', 'Ratings','Minimum_Cellar_Temp','Maximum_Cellar_Temp', 'Score']]\n\n# Printing first 10 rows of the dataset\nprint(\"\\n----------------------------\\n\",dataset.head(10))\n\n# Printing the summary of the dataset\nprint(\"\\n----------------------------\\n\")\nprint(dataset.info())\n\n\n# Classifying dependent and independent variables\n\n# All columns except the last column are independent features - (Selecting every column except Score)\nX = dataset.iloc[:,:-1].values\n\n# Only the last column is the dependent feature or the target variable(Score)\ny = dataset.iloc[:,-1].values\n\n# Creating training and test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)\n\n\n# Step 2\n\n########################### Support Vector Regression ###########################\n\n# Create a Support vector  Regressor and provide the dataset\nfrom sklearn.svm import SVR\nsvr = SVR(kernel='rbf') \n\n# Training the regressor with training data\nsvr.fit(X_train, y_train)\n\n# Predicting the salary for a test set\ny_pred = svr.predict(X_test)\n\n# Priniting the predicted values\nprint(\"\\n----------------------------\\nPredictions = \\n\",y_pred)\n\n# Calculating score from Root Mean Log Squared Error\ndef rmlse(y_test, y_pred):\n    error = np.square(np.log10(y_pred +1) - np.log10(y_test +1)).mean() ** 0.5\n    score = 1 - error\n    return score\n\n# Printing the score\nprint(\"\\n----------------------------\\nRMLSE Score = \", rmlse(y_test, y_pred))",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n----------------------------\n    ABV  Ratings Cellar Temperature  Score\n0  7.5        1              40-45   4.08\n1  5.3       22              40-45   3.82\n2  9.0        1              45-50   4.03\n3  4.6        1              35-40   4.00\n4  6.9        1              45-50   3.75\n5  7.9       32              40-45   4.26\n6  4.7      141              35-40   3.47\n7  5.6        1              40-45   3.70\n8  5.0        1              40-45   3.90\n9  5.4       12              40-45   3.79\n\n----------------------------\n    ABV  Ratings  Minimum_Cellar_Temp  Maximum_Cellar_Temp  Score\n0  7.5        1                   40                   45   4.08\n1  5.3       22                   40                   45   3.82\n2  9.0        1                   45                   50   4.03\n3  4.6        1                   35                   40   4.00\n4  6.9        1                   45                   50   3.75\n5  7.9       32                   40                   45   4.26\n6  4.7      141                   35                   40   3.47\n7  5.6        1                   40                   45   3.70\n8  5.0        1                   40                   45   3.90\n9  5.4       12                   40                   45   3.79\n\n----------------------------\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1631 entries, 0 to 1630\nData columns (total 5 columns):\nABV                    1631 non-null float64\nRatings                1631 non-null int64\nMinimum_Cellar_Temp    1631 non-null int64\nMaximum_Cellar_Temp    1631 non-null int64\nScore                  1631 non-null float64\ndtypes: float64(2), int64(3)\nmemory usage: 63.8 KB\nNone\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\n----------------------------\nPredictions = \n [3.87158722 0.09534496 3.66120693 3.88271879 4.17896989 3.57462616\n 3.71518472 0.09267043 3.83997801 3.58285154 3.72509269 3.57013683\n 3.24663481 3.71633733 3.57640345 3.75334967 3.75960791 3.86755239\n 3.87297783 3.79999041 4.11208339 4.21468538 0.06919579 3.5697965\n 3.5732781  0.92045952 3.92992621 3.60480767 3.84983296 3.91002229\n 3.744829   0.93154106 3.78525353 0.09627126 4.01162825 3.84586508\n 3.76224802 3.73020408 3.74027044 3.32529312 3.73310039 3.80514986\n 3.72509269 4.2284756  3.75161917 4.07548163 3.5697965  3.178862\n 3.38291591 4.05524978 3.93950443 3.58285154 4.05868202 3.94021578\n 3.67440595 3.73310039 0.09708641 3.79981332 3.78970317 3.63084579\n 3.60012073 3.84364282 3.72192536 0.10027302 3.46353756 4.27119602\n 3.67603143 3.6618162  3.69829291 3.5697965  3.95242528 3.91603431\n 3.33042942 3.93357794 3.96309561 3.93425023 3.5467629  3.72909462\n 4.0359174  3.70910729 3.74812125 3.70280664 3.56446058 3.66538873\n 4.27622616 3.46025526 3.75161917 0.17021601 4.00020386 3.57706198\n 3.76488681 3.32529312 0.92045952 4.07548163 0.1005397  3.55062094\n 3.5848276  3.45059197 3.92008039 3.51049811 3.90884567 3.62668237\n 3.76836664 3.55282558 3.77789911 3.56838931 3.58238202 3.56779392\n 4.0224885  3.79981332 3.72329734 3.75161917 3.56966207 3.64259306\n 0.06919579 3.8868434  3.71388627 3.49661807 3.61787102 3.8979626\n 4.08221077 0.14089089 4.04299511 3.77789911 3.51633427 3.25183438\n 3.5199875  3.7483681  3.78406385 4.30609893 3.956793   0.09328477\n 3.61988627 3.56849733 3.5689335  3.86295952 4.02841554 3.57046232\n 3.79449851 3.73663156 4.42450592 3.55322309 3.65245561 0.09267043\n 3.9945613  3.53168045 3.5697965  3.55987846 4.17742628 3.43235853\n 2.96984393 0.08081963 0.09188238 3.1932947  0.07919779 3.67135967\n 0.09020569 0.09480467 3.77946499 3.88160925 3.24303335 3.84983296\n 3.5697965  3.69007852 3.9938434  4.19121817 3.58285154 3.91037634\n 3.58125916 4.03973815 3.72978736 3.63375879 3.87843591 3.79292309\n 3.57840886 3.84882301 3.5697965  3.87306164 3.58932929 3.9003026\n 3.51990358 3.57462616 3.83310412 3.55728295 0.1000901  3.27094376\n 3.68161446 3.61474738 3.89412752 3.5697965  1.08148195 3.56979651\n 3.75148136 3.9293517  0.09267043 4.28300225 3.68161446 3.92550716\n 3.87306164 3.58692296 3.60231733 3.55985443 3.72727201 3.58510121\n 3.5697965  3.96749238 3.83310412 0.07207429 3.71265758 0.09708641\n 3.5697794  3.60443524 3.57462616 0.09482981 3.88957351 4.02044595\n 0.09482981 0.09020569 3.75334967 3.66972147 3.77789911 3.62230887\n 3.64259306 0.92045952 3.04101107 0.09708641 3.74970218 3.93304561\n 3.6810268  3.99038244 0.10738769 3.85209857 3.79449851 0.07207429\n 0.93191755 3.66962673 3.87158722 3.57823378 3.56977945 3.78238863\n 3.82580151 3.44128065 3.72978736 3.59635402 3.55985443 4.04925261\n 0.14089089 3.39974449 3.85031825 3.8868434  3.68641767 3.49239447\n 3.3423501  1.27540736 3.2796475  3.97797731 3.64259306 3.60810121\n 3.95510166 4.05524978 3.56557548 0.09267043 3.5697965  3.96781725\n 3.76498808 3.57184302 3.96781767 3.8627333  3.67484867 4.02274817\n 0.09351977 3.79264387 3.71983197 3.61787102 3.66560578 3.92992621\n 3.51049811 3.78417785 4.2177675  3.50701992 3.34777806 3.56319699\n 4.25480506 3.31139854 3.53993936 3.76109096 0.07207429 3.94008941\n 3.57011233 3.56978692 3.60883799 0.09534496 0.10738769 4.3832537\n 3.71014623 3.17399954 3.6400184  3.72978736 3.52468634 0.15044522\n 4.03001955 3.96781767 0.08081963 3.97853533 3.72303925 3.96523595\n 3.63084579 3.70212946 3.71422112 3.84582256 3.27566776 3.53993936\n 3.16319266 3.82040642 3.75161917 3.96781767 3.76654966 3.15244879\n 3.90884567 3.31890761 3.8938726  3.79806932 3.76976256 3.91185445\n 0.09534496 3.89081567 3.90823116]\n\n----------------------------\nRMLSE Score =  0.9334725731316009\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}